# PolicyDoc Agentic RAG System

An **Agentic PDF Question‚ÄìAnswering system** designed for **internal knowledge bases**, where the system intelligently decides **when to answer from a vector database** and **when to invoke external tools** if the information is not available locally.

The core focus of this project is **PDF-based knowledge ingestion and retrieval**, combined with **agentic decision-making** using LangChain + LangGraph.

This is a **production‚Äëminded learning project** emphasizing **system design, tool routing, CI/CD, and MLOps trade‚Äëoffs**, rather than just LLM prompting.
---

## üñºÔ∏è LangGraph Flowchart
![Flowchart](https://github.com/user-attachments/assets/90d8996b-a6fc-4f4c-96f0-f7fdcbe49c4f)

---

## Demo Video
https://github.com/user-attachments/assets/393724e8-d3c0-4df0-8320-4bf930a9e4d7

---

## üöÄ Key Features

- **PDF‚Äëcentric Knowledge Base**: Question answering over internal PDF documents (policies, FAQs, manuals)
- **Agentic Tool Routing**: The agent decides:
  - Use **vector search** when knowledge exists internally
  - Use **external tools / search** when knowledge is missing
- **Chroma Vector Store**: Persistent embeddings for document retrieval
- **Groq‚Äëpowered LLMs**: Low‚Äëlatency reasoning and response generation
- **Dockerized Backend**: Reproducible, platform‚Äëagnostic runtime
- **CI with GitHub Actions**: Docker build validation on every push
- **Cloud Deployment Exploration**: Render & Hugging Face Spaces (Docker)

---

## üß† Architecture Overview

```
User Question
   ‚Üì
Agent (LangGraph)
   ‚Üì
Decision Node
   ‚îú‚îÄ‚îÄ If answer exists ‚Üí Vector Retrieval (Chroma)
   ‚îî‚îÄ‚îÄ If missing ‚Üí External Tool / Search
   ‚Üì
LLM Reasoning (Groq)
   ‚Üì
Final Answer + Source Attribution
```
User Query
   ‚Üì
Flask API (Docker)
   ‚Üì
Agent (LangGraph / LangChain)
   ‚îú‚îÄ‚îÄ Retrieval Tool ‚Üí ChromaDB
   ‚îî‚îÄ‚îÄ LLM Reasoning ‚Üí Groq
   ‚Üì
Final Answer + Sources
```

### Why Agentic RAG?

Traditional RAG pipelines always retrieve documents, even when:
- The answer is already known
- The knowledge base is incomplete

This system instead:
- **Decides whether retrieval is needed**
- Falls back to **external tools** when internal PDFs are insufficient
- Enables more reliable internal knowledge assistants

This pattern closely mirrors **real enterprise knowledge systems**.

---

## üóÇÔ∏è Project Structure

```
policy-doc-agentic-rag/
‚îú‚îÄ‚îÄ .github/workflows/
‚îÇ   ‚îî‚îÄ‚îÄ ci_cd.yaml            # CI: Docker build validation
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ agents/               # Agent & tool definitions
‚îÇ   ‚îú‚îÄ‚îÄ config/               # Config loaders
‚îÇ   ‚îú‚îÄ‚îÄ ingestion/            # PDF ingestion & vectorstore creation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pdf_loader.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chunking.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chroma_store.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ingestion_pipeline.py
‚îÇ   ‚îî‚îÄ‚îÄ RAG/                  # Retrieval + embedding logic
‚îÇ       ‚îú‚îÄ‚îÄ embedding.py
‚îÇ       ‚îú‚îÄ‚îÄ main.py
‚îÇ       ‚îî‚îÄ‚îÄ utils.py
‚îú‚îÄ‚îÄ static/                   # Frontend assets (CSS/JS)
‚îú‚îÄ‚îÄ templates/                # HTML templates
‚îú‚îÄ‚îÄ data/                     # Local-only PDFs & vectorstore (not in CI/CD)
‚îÇ   ‚îú‚îÄ‚îÄ Software_FAQ.pdf
‚îÇ   ‚îî‚îÄ‚îÄ vectorstore/
‚îú‚îÄ‚îÄ app.py                    # Flask entrypoint
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```
policy-doc-agentic-rag/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îî‚îÄ‚îÄ frontend/
‚îÇ       ‚îî‚îÄ‚îÄ app.py          # Flask entrypoint
‚îú‚îÄ‚îÄ data/                   # (Local only) PDFs & vectorstore
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ requirements.txt        # Runtime dependencies
‚îú‚îÄ‚îÄ .github/workflows/
‚îÇ   ‚îî‚îÄ‚îÄ ci.yml              # CI: Docker build check
‚îî‚îÄ‚îÄ README.md
```

> ‚ö†Ô∏è **Note**: Binary artifacts (PDFs, vectorstores) are intentionally excluded from CI/CD to follow production best practices.

---

## üê≥ Docker Setup

### Build locally
```bash
docker build -t policy-doc-agentic-rag .
```

### Run locally
```bash
docker run -p 7860:7860 \
  -e GROQ_API_KEY=your_key \
  -e TAVILY_API_KEY=your_key \
  -e CHROMA_DB_PATH=/app/vectorstore \
  policy-doc-agentic-rag
```

The app binds to `$PORT` to support cloud platforms.

---

## üîê Environment Variables

| Variable | Description |
|-------|------------|
| `GROQ_API_KEY` | Groq API key for LLM inference |
| `TAVILY_API_KEY` | Optional web search tool |
| `CHROMA_DB_PATH` | Path to persisted Chroma vectorstore |
| `MODEL_NAME` | LLM model name (e.g. `llama3-70b-8192`) |

Secrets are injected via the deployment platform and **never committed**.

---

## ‚öôÔ∏è CI Pipeline (GitHub Actions)

The project includes a minimal but **industry-relevant CI pipeline**:

- Triggered on every push / PR to `main`
- Builds the Docker image
- Fails early on dependency or Dockerfile errors

This ensures that only **buildable artifacts** are deployed.

---

## üöÄ Deployment Notes

### Hugging Face Spaces (Docker)
- Used for ML-friendly memory limits
- Docker SDK provides full runtime control
- Secrets managed via Hugging Face Space settings

### CI/CD Strategy
- **CI**: GitHub Actions validates Docker builds on every push
- **CD**: Deployment experiments explored via Hugging Face Spaces
- Binary artifacts (PDFs, vectorstores) are intentionally excluded from automated deployment

---

## üë§ Author

**Om Tambat**  
AI / ML Engineer

This project is part of a hands-on journey into **Agentic AI systems, MLOps, and real-world deployment challenges**.

---

Thanks for reviewing üôå
